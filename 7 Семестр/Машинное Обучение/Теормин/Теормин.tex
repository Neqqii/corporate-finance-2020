\documentclass[a4paper, 12pt]{article}

%%% Матпакет
\usepackage{amsmath, amssymb, amscd, amsthm, amsfonts}
\usepackage{hyperref}
\usepackage{icomma}                  % "Умная" запятая: $0,2$ --- число, $0, 2$ --- перечисление
\DeclareMathOperator{\argmin}{argmin }
\DeclareMathOperator{\argmax}{argmax }
\DeclareMathOperator{\sgn}{sign }
\usepackage[ruled,section]{algorithm}
\usepackage[noend]{algorithmic}

%%% Страница
\usepackage{extsizes} % Возможность сделать 14-й шрифт
\usepackage{geometry} % Простой способ задавать поля
	\geometry{top=25mm}
	\geometry{bottom=25mm}
	\geometry{left=18mm}
	\geometry{right=14mm}
\usepackage{indentfirst}

%%%Стили
\usepackage{xcolor}
%\usepackage{sectsty}
%\allsectionsfont{\sffamily}
\usepackage{titlesec, blindtext, color} % подключаем нужные пакеты
\definecolor{gray75}{gray}{0.44} % определяем цвет
\definecolor{darkslateblue}{RGB}{74, 64, 164}
\newcommand{\hsp}{\hspace{14pt}} % длина линии в 20pt
\titleformat{\section}[hang]{\Large\bfseries}{\thesection\hsp\textcolor{gray75}{|}\hsp}{0pt}{\Large\bfseries\textcolor{darkslateblue}}

%%% Работа с русским языком
\usepackage{cmap}					% поиск в PDF
\usepackage{mathtext} 				% русские буквы в фомулах
\usepackage[T2A]{fontenc}			% кодировка
\usepackage[utf8]{inputenc}			% кодировка исходного текста
\usepackage[english, russian]{babel}	% локализация и переносы

\usepackage{soul} % Модификаторы начертания
\usepackage{csquotes} % Цитаты

%%% Теоремы
\theoremstyle{plain} % Это стиль по умолчанию, его можно не переопределять.
\newtheorem{theorem}{Теорема}[section]
\newtheorem{proposition}[theorem]{Утверждение}
\newtheorem{definition}{Определение}

\theoremstyle{definition} % "Утверждение"
\newtheorem{corollary}{Следствие}[theorem]
\newtheorem{problem}{Задача}[section]

\theoremstyle{remark} % "Примечание"
\newtheorem{example}{Пример}
\newtheorem{nota}{Примечание}

%%% Работа с картинками
\usepackage{graphicx}                % Для вставки рисунков
\graphicspath{{img/}}  				% папки с картинками
\setlength\fboxsep{3pt}              % Отступ рамки \fbox{} от рисунка
\setlength\fboxrule{1pt}             % Толщина линий рамки \fbox{}
\usepackage{wrapfig}                 % Обтекание рисунков текстом
\title{Машинное обучение \\ Теоретический минимум}
\author{ЭФ МГУ}
\date{2020}

%%% Работа с таблицами
\usepackage{array,tabularx,tabulary,booktabs} % Дополнительная работа с таблицами
\usepackage{longtable}                        % Длинные таблицы
\usepackage{multirow}                         % Слияние строк в таблице

\usepackage{hyperref}
\usepackage[usenames, dvipsnames, svgnames, table, rgb]{color}
\hypersetup{				                % Гиперссылки
    unicode=true,                           % русские буквы в раздела PDF
    pdftitle={Заголовок},                   % Заголовок
    pdfauthor={Автор},                      % Автор
    pdfsubject={Тема},                      % Тема
    pdfcreator={Создатель},                 % Создатель
    pdfproducer={Производитель},            % Производитель
    pdfkeywords={keyword1} {key2} {key3},   % Ключевые слова
    colorlinks=true,        	            % false: ссылки в рамках; true: цветные ссылки
    linkcolor=red,                          % внутренние ссылки
    citecolor=green,                        % на библиографию
    filecolor=magenta,                      % на файлы
    urlcolor=cyan                           % на URL
}

\begin{document}
\maketitle

\section{Матричное дифференцирование}

\section{Градиентный спуск}

\begin{definition}[Градиентный спуск]
	 метод нахождения локального экстремума (минимума или максимума) функции с помощью движения вдоль градиента.
\end{definition}

Для минимизации функции в направлении градиента используются методы одномерной оптимизации, например, метод золотого сечения. Также можно искать не наилучшую точку в направлении градиента, а какую-либо лучше текущей.

Наиболее простой в реализации из всех методов локальной оптимизации. Имеет довольно слабые условия сходимости, но при этом скорость сходимости достаточно мала (линейна). Шаг градиентного метода часто используется как часть других методов оптимизации, например, метод Флетчера — Ривса.

\subsection{Gradient Descent}

Основное свойство антиградиента~--- он указывает в сторону наискорейшего убывания функции в данной точке.
Соответственно, будет логично стартовать из некоторой точки, сдвинуться в сторону антиградиента,
пересчитать антиградиент и снова сдвинуться в его сторону и т.д.
Запишем это более формально.
Пусть~$w^{(0)}$~--- начальный набор параметров~(например, нулевой или сгенерированный из некоторого
случайного распределения).
Тогда градиентный спуск состоит в повторении следующих шагов до сходимости:
\begin{equation}
\label{eq:fullgrad}
    w^{(k)}
    =
    w^{(k - 1)}
    -
    \eta_k
    \nabla Q(w^{(k - 1)}).
\end{equation}
Здесь под~$Q(w)$ понимается значение функционала ошибки для набора параметров~$w$.

Через~$\eta_k$ обозначается длина шага, которая нужна для контроля скорости движения.
Можно делать её константной: $\eta_k = c$.
При этом если длина шага слишком большая, то есть риск постоянно <<перепрыгивать>> через точку минимума,
а если шаг слишком маленький, то движение к минимуму может занять слишком много итераций.
Иногда длину шага монотонно уменьшают по мере движения~--- например, по простой формуле
\[
    \eta_k
    =
    \frac{1}{k}.
\]

\subsection{Stochastic GD}

Проблема метода градиентного спуска~\eqref{eq:fullgrad} состоит в том,
что на каждом шаге необходимо вычислять градиент всей суммы~(будем его называть полным градиентом):
\[
    \nabla_w Q(w)
    =
    \sum_{i = 1}^{\ell}
        \nabla_w q_i(w).
\]
Это может быть очень трудоёмко при больших размерах выборки.
В то же время точное вычисление градиента может быть не так уж необходимо~---
как правило, мы делаем не очень большие шаги в сторону антиградиента,
и наличие в нём неточностей не должно сильно сказаться на общей траектории.
Опишем несколько способов оценивания полного градиента.

Оценить градиент суммы функций можно градиентом одного случайно взятого слагаемого:
\[
    \nabla_w Q(w)
    \approx
    \nabla_w q_{i_k}(w),
\]
где~$i_k$~--- случайно выбранный номер слагаемого из функционала.
В этом случае мы получим метод~\textbf{стохастического
градиентного спуска}~(stochastic gradient descent, SGD):
\[
    w^{(k)} = w^{(k - 1)} - \eta_k \nabla q_{i_k}(w^{(k - 1)}).
\]

Для выпуклого и гладкого функционала может быть получена
следующая оценка:
\[
    \mathbb{E} \left[
        Q(w^{(k)}) - Q(w^*)
    \right]
    =
    O(1 / \sqrt{k}).
\]
Таким образом, метод стохастического градиента имеет менее
трудоемкие итерации по сравнению с полным градиентом,
но и скорость сходимости у него существенно меньше.

Отметим одно важное преимущество метода стохастического градиентного спуска.
Для выполнения одного шага в данном методе требуется вычислить градиент лишь одного слагаемого~---
а поскольку одно слагаемое соответствует ошибке на одном объекте,
то получается, что на каждом шаге необходимо держать в памяти всего один объект из выборки.
Данное наблюдение позволяет обучать линейные модели на очень больших выборках:
можно считывать объекты с диска по одному, и по каждому делать один шаг метода SGD.

\section{Настройка гиперпараметров с помощью кросс-валидации}

\begin{definition}[Cross-validation]
	метод оценки аналитической модели и её поведения на независимых данных.
\end{definition}
	При оценке модели имеющиеся в наличии данные разбиваются на k частей. Затем на k−1 частях данных производится обучение модели, а оставшаяся часть данных используется для тестирования. Процедура повторяется k раз; в итоге каждая из k частей данных используется для тестирования. После этого качество каждой модели оценивается по тому блоку, который не участвовал в её обучении,
	и результаты усредняются. Получается оценка эффективности выбранной модели с наиболее равномерным использованием имеющихся данных.

	\[
	    \text{CV}
	    =
	    \frac{1}{k}
	    \sum_{i = 1}^{k}
	        Q\left( a_i(x), X_i \right).
	\]

\vspace{1em}
	Обычно кросс-валидация используется в ситуациях, где целью является предсказание, и хотелось бы оценить, насколько предсказывающая модель способна работать на практике. Один цикл кросс-валидации включает разбиение набора данных на части, затем построение модели на одной части (называемой \emph{тренировочным набором}), и валидация модели на другой части (называемой \emph{тестовым набором}). Чтобы уменьшить разброс результатов, разные циклы кросс-валидации проводятся на разных разбиениях, а результаты валидации усредняются по всем циклам.

\subsection{Гиперпараметры}

	В машинном обучении принято разделять подлежащие настройке величины
	на~\emph{параметры} и~\emph{гиперпараметры}.
	Параметрами называют величины, которые настраиваются по обучающей выборке~--- например,
	веса в линейной регрессии.
	К гиперпараметрам относят величины, которые контролируют сам процесс обучения и
	не могут быть подобраны по обучающей выборке.

	Хорошим примером гиперпараметра является коэффициент регуляризации~$\alpha$.
	Введение регуляризации мешает модели подгоняться под обучающие данные,
	и с точки зрения среднеквадратичной ошибки выгодно всегда брать~$\alpha = 0$.
	Разумеется, такой выбор не будет оптимальным с точки зрения качества на новых данных,
	и поэтому коэффициент регуляризации~(как и другие гиперпараметры) следует
	настраивать по отложенной выборке или с помощью кросс-валидации.

	При подборе гиперпараметров по кросс-валидации возникает проблема:
	мы используем отложенные данные, чтобы выбрать лучший набор гиперпараметров.
	По сути, отложенная выборка тоже становится обучающей, и показатели качества на ней
	перестают характеризовать обобщающую способность модели.
	В таких случаях выборку, на которой настраиваются гиперпараметры,
	называют валидационной, и при этом выделяют третий, тестовый набор данных,
	на которых оценивается качество итоговой модели.

\subsection{Распространенные типы кросс-валидации}

\subsubsection{Кросс-валидация по K блокам (K-fold cross-validation)}

В этом случае исходый набор данных разбивается на K одинаковых по размеру блока. Из K блоков один оставляется для тестирования модели, а остающиеся K-1 блока используются как тренировочный набор. Процесс повторяется K раз, и каждый из блоков используется один раз как тестовый набор. Получаются K результатов, по одному на каждый блок, они усредняются или комбинируются каким-либо другим способом, и дают одну оценку. Преимущество такого способа перед случайным сэмплированием (random subsampling) в том, что все наблюдения используются и для тренировки, и для тестирования модели, и каждое наблюдение используется для тестирования в точности один раз. Часто используется кросс-валидация на 10 блоках, но каких-то определенных рекомендаций по выбору числа блоков нет.

В послойной кросс-валидации блоки выбираются таким образом, что среднее значение ответа модели примерно равно по всем блокам.

\subsubsection{Валидация случайным сэмплированием (random subsampling)}

Этот метод случайным образом разбивает набор данных на тренировочный и тестовый наборы. Для каждого такого разбиения, модель подгоняется под тренировочные данные, а точность предсказания оценивается на тестовом наборе. Результаты затем усредняются по всем разбиениям. Преимущество такого метода перед кросс-валидацией на K блоках в том, что пропорции тренировочного и тестового наборов не зависят от числа повторений (блоков). Недостаток метода в том, что некоторые наблюдения могут ни разу не попасть в тестовый набор, тогда как другие могут попасть в него более, чем один раз. Другими словами, тестовые наборы могут перекрываться. Кроме того, поскольку разбиения проводятся случайно, результаты будут отличаться в случае повторного анализа.

В послойном варианте этого метода, случайные выборки генерируются таким способом, при котором средний ответ модели равен по тренировочному и тестовому наборам. Это особенно полезно, когда ответ модели бинарен, с неравными пропорциями ответов по данным.

\subsubsection{Поэлементная кросс-валидация (Leave-one-out, LOO)}

Здесь отдельное наблюдение используется в качестве тестового набора данных, а остальные наблюдения из исходного набора – в качестве тренировочного. Цикл повторяется, пока каждое наблюдение не будет использовано один раз в качестве тестового. Это то же самое, что и K-блочная кросс-валидация, где K равно числу наблюдений в исходном наборе данных.

\subsection{Применения кросс-валидации}

Кросс-валидация может использоваться для сравнения результатов различных процедур предсказывающего моделирования. Например, предположим, что мы интересуемся оптическим распознаванием символов, и рассматриваем варианты использования либо поддерживающих векторов (Support Vector Machines, SVM), либо k ближайших соседей (k nearest neighbors, KNN). С помощью кросс-валидации мы могли бы объективно сравнить эти два метода в терминах относительных коэффициентов их ошибок классификаций. Если мы будем просто сравнивать эти методы по их ошибкам на тренировочной выборке, KNN скорее всего покажет себя лучше, поскольку он более гибок и следовательно более склонен к переподгонке по сравнению с SVM.

Кросс-валидация также может использоваться для выбора параметров. Предположим, у нас есть 20 параметров, которые мы могли бы использовать в модели. Задача – выбрать параметры, использование которых даст модель с лучшими предсказывающими способностями. Если мы будем сравнивать подмножества параметров по их ошибкам на тестовом наборе, лучшие результаты получатся при использовании всех параметров. Однако с кросс-валидацией, модель с лучшей способностью к обобщению обычно включает только некоторое подмножество параметров, которые достаточно информативны.

\subsection{Ограничения и неверное использование кросс-валидации}

Кросс-валидация дает значимые результаты только когда тренировочный набор данных и тестовый набор данных берутся из одного источника, из одной популяции. В многих применениях предсказательных моделей структура изучаемой системы меняется со временем. Это может наводить систематические отклонения тренировочного и валидационного наборов данных. К примеру, если модель для предсказания цены акции тренируется на данных из определенного пятилетнего периода, нереалистично рассматривать последующий пятилетний период как выборку из той же самой популяции.

Если выполняется правильно, и наборы данных из одной популяции, кросс-валидация дает результат практически без смещений (bias). Однако, есть много способов использовать кросс-валидацию неправильно. В этом случае ошибка предсказания на реальном валидационном наборе данных скорее всего будет намного хуже, чем ожидается по результатам кросс-валидации.

\section{Формула классификации и регрессии в модели KNN. Примеры весов. Примеры метрик.}

\begin{definition}[k-Nearest-Neighbors]
	метрический алгоритм для автоматической классификации объектов или регрессии.
\end{definition}

Пусть дана обучающая выборка $X = (x_{i}, y_{i})^{l}_{i=1} \subset \mathbb{X}$ и ф-ия расстояния $\rho : \mathbb{X} \times \mathbb{X} \to [0, \infty]$. Расположим объекты обучающей выборки $X$ в порядке возрастания расстояний до $u$:
\[
	\rho(u, x_{u}^{(1)} \leqslant \rho(u, x_{u}^{(2)} \leqslant ... \leqslant \rho(u, x_{u}^{(l)}),
\]

где через $x_{u}^{i}$ обозначается $i$-й сосед объекта $u$. Алгоритм kNN относит объект к тому классу, представителей которого окажется больше среди всех $k$ его ближайших соседей:
\[
	a(u; X^{l}, k) = \underset{y \in Y}{\argmax} \sum^{k}_{i=1}w_{i}[y_{u}^{(i)} = y]
\]

Параметр $k$ обычно настраивается с помощью кросс-валидации.

В классическом методе $k$ ближайших соседей все объекты имеют единичные веса: $w_{i}=1$. Такой подход не является оптимальным.

\begin{example}
	Допустим, что $k=3$, $\rho(u, x_{u}^{(1)})=1$, $\rho(u, x_{u}^{(2)})=2$, $\rho(u, x_{u}^{(3)})=100$. Очевидно, третий сосед находится слишком далеко и не должен оказывать сильного влияния на результат. Для реализации этой идеи используются веса, обратно пропорциональные расстоянию:
\[
	w_{i} = K(\rho(u, x_{u}^{(i)})),
\]
где $K$-любая монотонно убывающая ф-ия.

С помощью метода kNN можно решать и задачи регрессии. Для этого нужно усреднить значения целевой ф-ии на соседях с весами:
\[
	a(u; X^{l}, k) = \frac{\sum^{k}_{i=1}w_{(i)}y_{(i)}}{\sum^{k}_{i=1}w_{(i)}}
\]

\subparagraph{Примеры весов}

\begin{itemize}
	\item
\end{itemize}

\subparagraph{Примеры метрик}

\begin{enumerate}
	\item \emph{Метрика Минковского}
	\item \emph{Расстояние Махалонобиса}
	\item \emph{Косинусная мера}
	\item \emph{Расстояние Джаккарда}
	\item \emph{Редакторское расстояние}
\end{enumerate}

\section{Определение линейного классификатора. Понятие отступа (Margin). Примеры верхних оценок на долю ошибок. Как обучаются веса?}

\subsection{Линейный классификатор}
Пусть $X \subset \mathbb{R}^{d}$ --- пространство объектов, $Y = {-1, +1}$ --- множество допустимых ответов, $X^{l} = (x_{i}, y_{i})^{l}_{i=1}$ --- обучающая выборка. Каждый объект $ x\in X$ описывается вещественным вектором $(x_{1}, ... , x_{d})\in \mathbb{R}^{d}$.

\textbf{Линейный классификатор} определяется следующим образом:

\[
	a(x,w) = \sgn(\langle w,x \rangle +b) = \sgn \left(\sum^{d}_{j=1}w_{j}x_{j}+b \right),
\]
где $w\in\mathbb{R}^{d}$ --- вектор весов, $b\in\mathbb{R}$ --- сдвиг (bias).\

Если не сказано иное, считается, что среди признаков есть константа $x_{0} = 1$, тогда необходимость вводить сдвиг $b$ отпадает, и линейный классификатор можно задавать как
\[
	a(x,w) = \sgn \langle x,w \rangle .
\]

\emph{Обучение линейного классфификатора} заключается в поиске вектора весов, на котором достигается минимум некоторого функционала качества.
\[
	w=\underset{w\in\mathbb{R}^{d}}{\argmin} Q(w,X^{l})
\]

Наиболее логичным функционалом для задачи классификации является число неверно классифицированных объектов.
\[
	Q(w,X^{l}) = \sum^{l}_{i=1}\left[ y_{i}(\langle w,x_{i} \rangle +b)<0\right] \to \underset{w}{min}
\]

У такого функционала есть большой недостаток --- он не является диффиренцируемым, из-за чего поиск оптимального вектора весов $w$ становится крайне трудной задачей. Для преодоления этой проблемы оптимизируется гладкая верхняя оценка на данный функционал.
\[
	Q(w,X^{l}) = \sum^{l}_{i=1}\left[ y_{i}(\langle w,x_{i} \rangle +b)<0\right] \leqslant \sum^{l}_{i=1}L\left[ y_{i}(\langle w,x_{i} \rangle +b)\right] \to \underset{w}{min}
\]
В качестве оценки $L(M)$ можно использовать, например, логистическую функцию потерь $L(M) = \log(1+e^{-M})$

\subsection{Margin (отступ)}

\begin{definition}
		Отступом (margin) объекта $x_{i} \in \mathbb{X}^{l}$ относительно алгоритма классификации, имеющего вид $a(u) = \underset{y\in Y}{\argmax} \Gamma_{y}(u)$, называется величина
\end{definition}
\[
	M(x_{i}) = \Gamma_{y_{i}}(x_{i}) - \underset{y\in Y}{\max} \Gamma_{y}(x_{i})
\]

Отступ показывает степень типичности объекта. Отступ отрицателен тогда и только тогда, когда алгоритм допускает ошибку на данном объекте. В зависимости от значений отступа обучающие объекты условно делятся на пять типов, в порядке убывания отступа: эталонные, неинформативные, пограничные, ошибочные, шумовые.

\section{Подходы one-vs-one и one-vs-rest для линейных классификаторов.}

Пусть рассматривается задача классификации с $ C $
 классами.

\subsection{One-vs-all}

\begin{enumerate}
	\item Обучим на всех объектах тренировочной выборки $ C $ бинарных классификаторов типа "принадлежит ли объект $ i $-ому классу".
	\item В результате получим $ C $ классификаторов $ f_c(x) $.
	\item Ответ ищется, как $ \hat y(x) = \underset{c \in [1, \dots, C] }{\operatorname{argmax}} f_c(x) $.
\end{enumerate}

\subsection{One-vs-one}

\begin{enumerate}
	\item Обучим $ \dfrac{C(C - 1)}{2} $
 бинарных классификаторов следующим образом: для каждой пары $ i, j \in [1, \dots, C], i \ne j $
 обучим бинарный классификатор $ f_{i, j}(x) $
 на тех объектах тренировочной выборки, ответ которых принимает значение $ i $
 или $ j $
.
	\item В результате получим $ \dfrac{C(C - 1)}{2} $
 классификаторов $ f_{i, j}(x) $
.
	\item На этапе предсказания каждый из всех обученных классификаторов возвращает индикатор принадлежности соответствующему классу. Тот класс, за который проголосовало большинство и будет ответом на данном объекте:
\end{enumerate}

$ \hat y(x) = \underset{c \in [1, \dots, C] }{\operatorname{argmax}} \sum \limits_{i \ne j \in [1, \dots, C]} \mathbb I [f_{i, j}(x) == c] $
.

\section{Проклятие размерности}

Если используемая метрика $\rho(x,x′)$ основана на суммировании различий по всем признакам, а число признаков очень велико, то все точки выборки могут оказаться практически одинаково далеки друг от друга. Тогда парзеновские оценки плотности становятся неадекватны. Это явление называют \emph{проклятием размерности}. Выход заключается в понижении размерности с помощью преобразования пространства признаков, либо путём отбора информативных признаков. Можно строить несколько альтернативных метрик в подпространствах меньшей размерности, и полученные по ним алгоритмы классификации объединять в композицию.

\section{Матрица ошибок (confusion matrix). Определение accuracy, precision, recall, f1-measure.}
Это способ разбить объекты на четыре категории в зависимости от комбинации истинного ответа и ответа алгоритма. Через элементы этой матрицы можно, например, выразить долю правильных ответов:
\[
	accuracy = \frac{TP+TN}{TP+FP+FN+TN}
\]
\[
	precision = \frac{TP}{TP+FP}
\]
\[
	recall = \frac{TP}{TP+FN}
\]
Точность \emph{(precision)} показывает, какая доля объектов, выделенных классификатором как положительные, действительно является таковыми. Полнота \emph{(recall)} показывает, какая часть положительных ответов была выделена классификатором.

Существует несколько способов получить один критерий качества на основе точности и полноты. Один из них --- $F$-мера, гармоническое среднее точности и полноты:
\[
	F = \frac{2\times precision \times recall}{precision+recall}
\]
Среднее гармоническое обладает важным свойством --- оно близко к нулю, если хотя бы один из аргументов близок к нулю. Именно поэтому оно является более предпочтительным, чем среднее арифметическое.
\section{ROC-кривая, AUC-ROC.}

\subsection{ROC-кривая}

\begin{definition}[ROC-curve]
	графичекая характеристика качества бинарного классификатора, зависимость доли верных положительных классификаций от доли ложных положительных классификаций при варьировании порога решающего правила.
\end{definition}
	Преимуществом ROC-кривой является её инвариантность относительно отношения цены ошибки I и II рода.

\subparagraph{Построение}
	\begin{enumerate}
		\item \textbf{Вход}

			обучающая выборка $X^{l}$; $f(x) = \langle w,x \rangle$ --- дискриминантная функция;
		\item \textbf{Выход}

			$\{ (FPR_{i}, TPR_{i})\}_{i=0}^{l}$ --- последовательность точек $ROC$-кривой;
			$AUC$ --- площадь под $ROC$-кривой.
		\item \textbf{Алгоритм:}
		\begin{enumerate}
			\item[1:] $l^{-} = \sum^{l}_{i=0}[y_{i}=-1]$ --- число объектов класса $-1$;

			$l^{+} = \sum^{l}_{i=0}[y_{i}=+1]$ --- число объектов класса $+1$;
			\item[2:] упорядочить выборку $X^{l}$ по убыванию значений $f(x_{i})$;
			\item[3:] поставить первую точку в начало координат:

			$(FPR_{0}, TPR_{0}) := (0,0); AUC := 0$;
			\item[4:] Для i := 1, ... , l
			\item[4a:] Если $y_{i} = -1$, то

			Сместиться на один шаг вправо:

			$FPR_{i} := FPR_{i-1} + \frac{1}{l^{-}}$; $TPR_{i} := TPR_{i-1}$;

			$AUC := AUC + \frac{1}{l^{-}}\times TPR_{i}$;
			\item[4b:] иначе

			Сместиться на один шаг вверх:

			$FPR_{i} := FPR_{i-1}$; $TPR_{i} := TPR_{i-1} + \frac{1}{l^{+}}$;
		\end{enumerate}
	\end{enumerate}

\subsection{AUC-ROC}

\begin{definition}[AUC-ROC]
	Площадь под ROC-кривой AUC (Area Under Curve) является агрегированной характеристикой качества классификации, не зависящей от соотношения цен ошибок.
\end{definition}
Чем больше значение AUC, тем «лучше» модель классификации. Данный показатель часто используется для сравнительного анализа нескольких моделей классификации.

\section{Определение решающего дерева. Критерии расщепления в случае задачи классификации и регрессии.}

\subsection{Решающие деревья}

Рассмотрим бинарное дерево, в котором:
\begin{itemize}
    \item каждой внутренней вершине~$v$ приписана функция~(или предикат)~$\beta_v: \XX \to \{0, 1\}$;
    \item каждой листовой вершине~$v$ приписан прогноз~$c_v \in Y$~(в случае с классификацией
        листу также может быть приписан вектор вероятностей).
\end{itemize}
Рассмотрим теперь алгоритм~$a(x)$, который стартует из корневой вершины~$v_0$
и вычисляет значение функции~$\beta_{v_0}$.
Если оно равно нулю, то алгоритм переходит в левую дочернюю вершину, иначе в правую,
вычисляет значение предиката в новой вершине и делает переход или влево, или вправо.
Процесс продолжается, пока не будет достигнута листовая вершина;
алгоритм возвращает тот класс, который приписан этой вершине.
Такой алгоритм называется~\textbf{бинарным решающим деревом}.

На практике в большинстве случаев используются одномерные предикаты~$\beta_v$,
которые сравнивают значение одного из признаков с порогом:
\[
    \beta_v(x; j, t)
    =
    [x_j < t].
\]
Существуют и многомерные предикаты, например:
\begin{itemize}
    \item линейные~$\beta_v(x) = [\langle w, x \rangle < t]$;
    \item метрические~$\beta_v(x) = [\rho(x, x_v) < t]$, где точка~$x_v$ является одним из объектов выборки любой точкой
        признакового пространства.
\end{itemize}
Многомерные предикаты позволяют строить ещё более сложные разделяющие поверхности,
но очень редко используются на практике~--- например, из-за того,
что усиливают и без того выдающиеся способности деревьев к переобучению.

\subsection{Критерии расщепления}
При построении дерева необходимо задать~\emph{функционал качества},
на основе которого осуществляется разбиение выборки на каждом шаге.
Обозначим через~$R_m$ множество объектов, попавших в вершину, разбиваемую на данном шаге,
а через~$R_\ell$ и~$R_r$~--- объекты, попадающие в левое и правое поддерево соответственно
при заданном предикате.
Мы будем использовать функционалы следующего вида:
\[
    Q(R_m, j, s)
    =
    H(R_m)
    -
    \frac{|R_\ell|}{|R_m|}
    H(R_\ell)
    -
    \frac{|R_r|}{|R_m|}
    H(R_r).
\]
Здесь~$H(R)$~--- это~\emph{критерий информативности}~(impurity criterion),
который оценивает качество распределения целевой переменной среди объектов множества~$R$.
Чем меньше разнообразие целевой переменной, тем меньше должно быть значение критерия информативности~---
и, соответственно, мы будем пытаться минимизировать его значение.
Функционал качества~$Q(R_m, j, s)$ мы при этом будем максимизировать.

Как уже обсуждалось выше, в каждом листе дерево будет выдавать константу~--- вещественное число, вероятность
или класс.
Исходя из этого, можно предложить оценивать качество множества объектов~$R$ тем,
насколько хорошо их целевые переменные предсказываются константой~(при оптимальном выборе этой константы):
\[
    H(R)
    =
    \min_{c \in \YY}
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
        L(y_i, c),
\]
где~$L(y, c)$~--- некоторая функция потерь.
Далее мы обсудим, какие именно критерии информативности часто используют в задачах регрессии и классификации.

\subsubsection{Регрессия}
Как обычно, в регрессии выберем квадрат отклонения в качестве функции потерь.
В этом случае критерий информативности будет выглядеть как
\[
    H(R)
    =
    \min_{c \in \YY}
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
        (y_i - c)^2.
\]
Как известно, минимум в этом выражении будет достигаться на среднем значении целевой переменной.
Значит, критерий можно переписать в следующем виде:
\[
    H(R)
    =
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
    \left(
        y_i
        -
        \frac{1}{|R|}
        \sum_{(x_j, y_j) \in R}
            y_j
    \right)^2.
\]
Мы получили, что информативность вершины измеряется её дисперсией~---
чем ниже разброс целевой переменной, тем лучше вершина.
Разумеется, можно использовать и другие функции ошибки~$L$~---
например, при выборе абсолютного отклонения мы получим в качестве критерия среднее абсолютное отклонение от медианы.

\subsubsection{Классификация}
Обозначим через~$p_{k}$ долю объектов класса~$k$~($k \in \{1, \dots, K\}$), попавших в вершину~$R$:
\[
    p_{k}
    =
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
        [y_i = k].
\]
Через~$k_*$ обозначим класс, чьих представителей оказалось больше всего среди объектов,
попавших в данную вершину: $k_* = \argmax_k p_{k}$.

\subparagraph{Ошибка классификации}
Рассмотрим индикатор ошибки как функцию потерь:
\[
    H(R)
    =
    \min_{c \in \YY}
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
        [y_i \neq c].
\]
Легко видеть, что оптимальным предсказанием тут будет наиболее популярный класс~$k_*$~---
значит, критерий будет равен следующей доле ошибок:
\[
    H(R)
    =
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
        [y_i \neq k_*]
    =
    1 - p_{k_*}.
\]

Данный критерий является достаточно грубым,
поскольку учитывает частоту~$p_{k_*}$ лишь одного класса.

\subparagraph{Критерий Джини}
Рассмотрим ситуацию, в которой мы выдаём в вершине не один класс,
а распределение на всех классах~$c = (c_1, \dots, c_K)$, $\sum_{k = 1}^{K} c_k = 1$.
Качество такого распределения можно измерять, например, с помощью критерия Бриера~(Brier score):
\[
    H(R)
    =
    \min_{\sum_k c_k = 1}
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
    \sum_{k = 1}^{K}
        (c_k - [y_i = k])^2.
\]

Можно показать, что оптимальный вектор вероятностей состоит из долей классов~$p_k$:
\[
    c_* = (p_1, \dots, p_K)
\]
Если подставить эти вероятности в исходный критерий информативности
и провести ряд преобразований, то мы получим критерий~Джини:
\[
    H(R)
    =
    \sum_{k = 1}^{K}
        p_k (1 - p_k).
\]

\subparagraph{Энтропийный критерий}
Мы уже знакомы с более популярным способом оценивания качества
вероятностей~--- логарифмическими потерями, или логарифмом правдоподобия:
\[
    H(R)
    =
    \min_{\sum_k c_k = 1} \left(
        -
        \frac{1}{|R|}
        \sum_{(x_i, y_i) \in R}
        \sum_{k = 1}^{K}
            [y_i = k]
            \log c_k
    \right).
\]
Для вывода оптимальных значений~$c_k$ вспомним, что все значения~$c_k$
должны суммироваться в единицу.
Как известного из методов оптимизации, для учёта этого ограничения необходимо искать
минимум лагранжиана:
\[
    L(c, \lambda)
    =
    -
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
    \sum_{k = 1}^{K}
        [y_i = k]
        \log c_k
    +
    \lambda
    \sum_{k = 1}^{K}
        c_k
    \to
    \min_{c_k}
\]
Дифференцируя, получаем:
\[
    \frac{\partial}{\partial c_k}
    L(c, \lambda)
    =
    -
    \frac{1}{|R|}
    \sum_{(x_i, y_i) \in R}
        [y_i = k]
        \frac{1}{c_k}
    +
    \lambda
    =
    - \frac{p_k}{c_k}
    +
    \lambda
    =
    0,
\]
откуда выражаем~$c_k = p_k / \lambda$.
Суммируя эти равенства по~$k$, получим
\[
    1 = \sum_{k = 1}^{K} c_k = \frac{1}{\lambda} \sum_{k = 1}^{K} p_k = \frac{1}{\lambda},
\]
откуда~$\lambda = 1$.
Значит, минимум достигается при~$c_k = p_k$, как и в предыдущем случае.
Подставляя эти выражения в критерий, получим, что он будет представлять собой энтропию распределения классов:
\[
    H(R)
    =
    -
    \sum_{k = 1}^{K}
        p_k
        \log p_k.
\]

Из теории вероятностей известно, что энтропия ограничена снизу нулем, причем минимум достигается на вырожденных
распределениях~($p_i = 1$, $p_j = 0$ для~$i \neq j$).
Максимальное же значение энтропия принимает для равномерного распределения.
Отсюда видно, что энтропийный критерий отдает предпочтение более <<вырожденным>> распределениям классов
в вершине.

\section{Постановка задачи PCA. Как выбирать оптимальную размерность маломерного пространства?}

\subsection{Постановка задачи PCA}

В машинном обучении часто возникает задача уменьшения размерности
признакового пространства.
Для этого можно, например, удалять признаки, которые слабо коррелируют с целевой переменной;
выбрасывать признаки по одному и проверять качество модели на тестовой выборке;
перебирать случайные подмножества признаков в поисках лучших наборов.
Ещё одним из подходов к решению задачи является поиск новых признаков,
каждый из которых является линейной комбинацией исходных признаков.
В случае использования квадратичной функции ошибки при поиске
такого приближения получается~\emph{метод главных компонент}~(principal
component analysis, PCA),
о котором и пойдет речь.

Пусть~$X \in \mathbb{R}^{\ell \times D}$~--- матрица <<объекты-признаки>>,
где~$\ell$~--- число объектов, а~$D$~--- число признаков.
Поставим задачу уменьшить размерность пространства до~$d$.
Будем считать, что данные являются центрированными~--- то есть среднее
в каждом столбце матрицы~$X$ равно нулю.

Будем искать главные компоненты~$u_1, \dots, u_D \in \mathbb{R}^D$, которые удовлетворяют
следующим требованиям:
\begin{enumerate}
    \item Они ортогональны:~$\langle u_i, u_j \rangle = 0$, $i \neq j$;
    \item Они нормированы:~$\|u_i\|^2 = 1$;
    \item При проецировании выборки на компоненты~$u_1, \dots, u_d$ получается
        максимальная дисперсия среди всех возможных способов выбрать~$d$ компонент.
\end{enumerate}

\subparagraph{Альтернативные постановки}

Существует несколько других постановок задачи понижения размерности,
приводящих к методу главных компонент.

Первый способ основан на матричном разложении.
Будем искать матрицу с новыми признаковыми описаниями~$Z \in \mathbb{R}^{\ell \times d}$
и матрицу проецирования~$U \in \mathbb{R}^{D \times d}$,
произведение которых даёт лучшее приближение исходной матрицы~$X$:
\[
    \| X - Z U^T \|^2
    \to
    \min_{Z, U}
\]
Решением данной задачи также являются собственные векторы ковариационной матрицы.

Второй способ состоит в поиске такого линейного подпространства,
что расстояние от исходных объектов до их проекций на это подпространство
будет минимальным.
В этом случае задача оказывается эквивалентной задаче максимизации дисперсии проекций.

\subsection{Выбор оптимальной размерности}

\section{Постановка задачи кластеризации. Алгоритм K-means.}

\subsection{Кластеризация}

Пусть дана выборка объектов~$X = (x_i)_{i = 1}^{\ell}$, $x_i \in \XX$.
В задаче кластеризации требуется выявить в данных~$K$ кластеров~---
таких областей, что объекты внутри одного кластера похожи друг на друга,
а объекты из разных кластеров друг на друга не похожи.
Более формально, требуется построить алгоритм~$a: \XX \to \{1, \dots, K\}$,
определяющий для каждого объекта номер его кластера;
число кластеров~$K$ может либо быть известно, либо являться параметром.

Кластеризовать можно много что: новости по сюжетам, пиксели на изображении по принадлежности объекту,
музыку по жанрам, сообщения на форуме по темам, клиентов по типу поведения.

\subsection{K-Means}
Одним из наиболее популярных методов кластеризации является \emph{K-Means},
который оптимизирует внутрикластерное расстояние,
в котором используется квадрат евклидовой метрики.

Заметим, что в данном функционале имеется две степени свободы:
центры кластеров~$c_k$ и распределение объектов по кластерам~$a(x_i)$.
Выберем для этих величин произвольные начальные приближения,
а затем будем оптимизировать их по очереди:
\begin{enumerate}
    \item Зафиксируем центры кластеров.
        В этом случае внутрикластерное расстояние будет минимальным,
        если каждый объект будет относиться к тому кластеру, чей центр является ближайшим:
        \[
            a(x_i)
            =
            \underset{1 \leq k \leq K}{\argmin}~
                \rho(x_i, c_k).
        \]
    \item Зафиксируем распределение объектов по кластерам.
        В этом случае внутрикластерное расстояние с квадратом евклидовой метрики можно продифференцировать
        по центрам кластеров и вывести аналитические формулы для них:
        \[
            c_k
            =
            \frac{1}{\sum_{i = 1}^{\ell} [a(x_i) = k]}
            \sum_{i = 1}^{\ell}
                [a(x_i) = k] x_i.
        \]
\end{enumerate}

Повторяя эти шаги до сходимости, мы получим некоторое распределение объектов по кластерам.
Новый объект относится к тому кластеру, чей центр является ближайшим.

Результат работы метода K-Means существенно зависит от начального приблжения.
Существует большое количество подходов к инициализации;
одним из наиболее успешных считается k-means++.

\section{Сингулярное разложение (SVD) определение, его связь с PCA.}

\subsection{Определение}

Предположим, что $ X \in \mathbb{R}^{N \times D}$, $rank X = R $
.
Тогда существуют
\[
 	U \in \mathbb{R}^{N \times R}
\]
\[
	\Sigma \in \mathbb{R}^{R \times R}
\]
\[
	V^T \in \mathbb{R}^{R \times D}
\]

такие, что
\[
	X = U\Sigma V^T
\]
\[
	\Sigma = diag\{\sigma_1, ..., \sigma_R\}, \sigma_1 \geq \sigma_2 \geq ... \geq \sigma_R > 0
\]
\[
	U^TU=I, V^TV=I
\]
.
Для любой матрицы существует ее SVD-разложение. Оно определено с точностью до перестановок одинаковых собственных значений $ \sigma_i^2, i = 1 \dots R $
, и соответствующих им собственных векторов. Если же все собственные значения уникальны, то разложение единственно.

 Свойства SVD-разложения и Связь с главными компонентами

\subsection{Связь с PCA}

Приглядимся поближе к SVD-разложению. Что мы увидим?
\begin{enumerate}
	\item Столбцы $ U $
    — ортонормированный базис (ОНБ) столбцов $ X $
   .
   	\item Строки $ V^T $
    — ОНБ строк $ X $
   .
   	\item Строки $ U $
    — нормированные координаты строк $ V^T $
   .
   	\item $ \Sigma $
    — масштабирование, то есть $ \sigma_1, \dots, \sigma_R $
    — величины "вхождения" каждой строки $ V^T $
   .
   	\item $ X X^T U = U \Sigma^2 \Rightarrow $
    столбцы $ U $
    — собственные векторы матрицы $ X X^T $
   , отвечающие собственным значениям  $ \sigma_1^2, \dots, \sigma_R^2 $
   .
   	\item $ X^T X V = V \Sigma^2  \Rightarrow $
    столбцы $ V $
    — собственные векторы матрицы $ X^T X $
   , отвечающие собственным значениям  $ \sigma_1^2, \dots, \sigma_R^2 $
   , а значит, матрица $ V $
    состоит из первых $ R $
    главных компонент.
\end{enumerate}

\section{l-1, l-2 регуляризация в задаче линейной регрессии и классификации. Какая из них позволяет отбирать признаки и почему?}

\subsection{Виды регуляризации}

Часто регуляризация представляет собой просто некоторую добавку $ R(w) $
 (где $ w $
 — параметры модели) к функции потерь $ L(f(x, w), y) $
 так что задача приобретает вид:

\[
	\min_{\displaystyle w} \sum_{i=1}^N L(f(x_i, w), y_i)) + \lambda R(w)
\]

Часто используемые $ R(w) $:
\begin{itemize}
	\item L2 регуляризация — $ R(w) = ||w||_2^2 = \sum_{i=1}^d {w_i}^2 $
	\item L1 регуляризация — $ R(w) = ||w||_1 = \sum_{i=1}^d |w_i| $
	\item ElasticNet регуляризация — $ R(w) = \lambda_1 ||w||_2^2 + \lambda_2 ||w||_1 $
\end{itemize}

\subsection{Отбор признаков}

Предположим, что перед нами стоит задача линейной регрессии с L1 регуляризацией (lasso regression):

\begin{itemize}
	\item $ f(x, w) = w^Tx + w_0 $
	\item $ L(w) = \min_{\displaystyle w} \sum_{i=1}^N (w^Tx_i + w_0 - y_i)^2 + \lambda ||w||_1 $
\end{itemize}

L1 регуляризация приведет к занулению весов некоторых признаков так как градиент равен:
\[
	\nabla_w L(w) = \sum_{i=1}^N 2x_i^T (w^Tx_i + w_0 - y_i) + \lambda \sgn(w)
\]

Соответственно при достаточно большом $ \lambda $
 некоторые признаки обязательно обнулятся. Тогда отбираются те признаки, при которых вес не равен нулю.

\section{Постановка задачи обучения логистической регрессии.}

\section{Постановка задачи SVM (Soft & Hard margin).}

\begin{definition}[Support Mector Machine]
	один из наиболее популярных методов обучения, который применяется для решения задач классификации и регрессии. Основная идея метода заключается в построении гиперплоскости, разделяющей объекты выборки оптимальным способом. Алгоритм работает в предположении, что чем больше расстояние (зазор) между разделяющей гиперплоскостью и объектами разделяемых классов, тем меньше будет средняя ошибка классификатора.
\end{definition}

Рассмотрим задачу бинарной классификации, в которой объектам из $X=\mathbb{R}^n$ соответствует один из двух классов $Y = \{-1, +1\}$.

Пусть задана обучающая выборка пар "объект-ответ": $T^\ell = (\vec{x}_i, y_i)_{i=1}^\ell$. Необходимо построить алгоритм классификации $a(\vec{x}) : X \to Y$.

Рассмотрим подход к построению функции потерь,
основанный на максимизации зазора между классами.
Будем рассматривать линейные классификаторы вида
\[
    a(x) = \sign (\langle w, x \rangle + b), \qquad w \in \RR^d, b \in \RR.
\]

\subsection{Разделимый случай}
Будем считать, что существуют такие параметры~$w_*$ и~$b_*$,
что соответствующий им классификатор~$a(x)$ не допускает ни одной ошибки
на обучающей выборке.
В этом случае говорят, что выборка~\emph{линейно разделима}.

Пусть задан некоторый классификатор~$a(x) = \sign (\langle w, x \rangle + b)$.
Заметим, что если одновременно умножить параметры~$w$ и~$b$
на одну и ту же положительную константу,
то классификатор не изменится.
Распорядимся этой свободой выбора и отнормируем параметры так, что
\begin{equation}
\label{eq:svmNormCond}
    \min_{x \in X} | \langle w, x \rangle + b| = 1.
\end{equation}
Можно показать, что расстояние от произвольной точки~$x_0 \in \RR^d$ до гиперплоскости,
определяемой данным классификатором, равно
\[
    \rho(x_0, a)
    =
    \frac{
        |\langle w, x \rangle + b|
    }{
        \|w\|
    }.
\]
Тогда расстояние от гиперплоскости до ближайшего объекта обучающей выборки равно
\[
    \min_{x \in X}
    \frac{
        |\langle w, x \rangle + b|
    }{
        \|w\|
    }
    =
    \frac{1}{\|w\|} \min_{x \in X} |\langle w, x \rangle + b|
    =
    \frac{1}{\|w\|}.
\]
Данная величина также называется~\emph{отступом~(margin)}.

Таким образом, если классификатор без ошибок разделяет обучающую выборку,
то ширина его разделяющей полосы равна~$\frac{2}{\|w\|}$.
Известно, что максимизация ширины разделяющей полосы приводит
к повышению обобщающей способности классификатора~\cite{mohri12foundations}.
Вспомним также, что на повышение обобщающей способности направлена и регуляризация,
которая штрафует большую норму весов~--- а чем больше норма весов,
тем меньше ширина разделяющей полосы.

Итак, требуется построить классификатор, идеально разделяющий обучающую выборку,
и при этом имеющий максимальный отступ.
Запишем соответствующую оптимизационную задачу,
которая и будет определять метод опорных векторов для линейно разделимой выборки~(hard margin support vector machine):
\begin{equation}
\label{eq:svmSep}
    \left\{
        \begin{aligned}
            & \frac{1}{2} \|w\|^2 \to \min_{w, b} \\
            & y_i \left(
                \langle w, x_i \rangle + b
            \right) \geq 1, \quad i = 1, \dots, \ell.
        \end{aligned}
    \right.
\end{equation}
Здесь мы воспользовались тем, что линейный классификатор дает правильный ответ
на объекте~$x_i$ тогда и только тогда, когда~$y_i (\langle w, x_i \rangle + b) \geq 0$.
Более того, из условия нормировки~\eqref{eq:svmNormCond} следует,
что~$y_i (\langle w, x_i \rangle + b) \geq 1$.

В данной задаче функционал является строго выпуклым, а ограничения линейными,
поэтому сама задача является выпуклой и имеет единственное решение.
Более того, задача является квадратичной и может быть решена крайне эффективно.

\subsection{Неразделимый случай}
Рассмотрим теперь общий случай, когда выборку
невозможно идеально разделить гиперплоскостью.
Это означает, что какие бы~$w$ и~$b$ мы не взяли,
хотя бы одно из ограничений в задаче~\eqref{eq:svmSep}
будет нарушено:
\[
    \exists x_i \in X:\
    y_i \left(
        \langle w, x_i \rangle + b
    \right) < 1.
\]
Сделаем эти ограничения <<мягкими>>, введя штраф~$\xi_i \geq 0$ за их нарушение:
\[
    y_i \left(
        \langle w, x_i \rangle + b
    \right) \geq 1 - \xi_i, \quad i = 1, \dots, \ell.
\]

Отметим, что если отступ объекта лежит между нулем и
единицей~($0 \leq y_i \left( \langle w, x_i \rangle + b \right) < 1$),
то объект верно классифицируется, но имеет ненулевой штраф~$\xi > 0$.
Таким образом, мы штрафуем объекты за попадание внутрь разделяющей полосы.

Величина~$\frac{1}{\|w\|}$ в данном случае называется~\emph{мягким отступом~(soft margin)}.
С одной стороны, мы хотим максимизировать отступ, с другой~--- минимизировать
штраф за неидеальное разделение выборки~$\sum_{i = 1}^{\ell} \xi_i$.
Эти две задачи противоречат друг другу: как правило, излишняя подгонка под
выборку приводит к маленькому отступу, и наоборот~--- максимизация отступа
приводит к большой ошибке на обучении.
В качестве компромисса будем минимизировать взвешенную сумму двух указанных величин.
Приходим к оптимизационной задаче,
соответствующей методу опорных векторов для линейно неразделимой выборки~(soft margin support vector machine)
\begin{equation}
\label{eq:svmUnsep}
    \left\{
        \begin{aligned}
            & \frac{1}{2} \|w\|^2 + C \sum_{i = 1}^{\ell} \xi_i \to \min_{w, b, \xi} \\
            & y_i \left(
                \langle w, x_i \rangle + b
            \right) \geq 1 - \xi_i, \quad i = 1, \dots, \ell, \\
            & \xi_i \geq 0, \quad i = 1, \dots, \ell.
        \end{aligned}
    \right.
\end{equation}
Чем больше здесь параметр~$C$, тем сильнее мы будем настраиваться на обучающую выборку.

Данная задача также является выпуклой и имеет единственное решение.

\section{Определение ядровой функции (K(x, z)). Обобщение SVM с помощью ядер.}

Пусть $X$ – некоторое пространство. Тогда отображение $K:\ X \times X \to \mathbb R$ называется \emph{ядром} или \emph{kernel function}, если оно представимо в виде:

$K \left(x,x^{\prime} \right) = \left< \psi(x), \psi (x^{\prime}) \right>_H $, где $ \psi $ – некоторое отображение $\psi:\ X \to H $.

\subsection{Обобщение SVM с помощью ядер.}

Вместо скалярного произведения можно использовать ядра:
\[
	\begin{cases} \sum_{i=1}^{l} \lambda_i - \frac{1}{2} \sum_{i,j=1}^{l} \lambda_i \lambda_j y_i y_j K(x_i,x_j) \rightarrow \underset{\lambda}{max} \\ 0 \le \lambda_i \le\ C,\ i=1,2,...,l \\ \sum_{i=1}^{l} \lambda_i y_i = 0 \\ \end{cases}
\]


В этом случае классификатор будет иметь вид:

\[
	a(x)= sign(\sum_{i=1}^{l} \lambda_i y_i K(x_i, x) + b)
\]


\section{Постановка задачи гребневой регрессии (Ridge-regression). Формула оптимальных весов для неё.}

\textbf{Ридж-регрессия} (англ. ridge regression) - это один из методов понижения размерности. Часто его применяют для борьбы с переизбыточностью данных, когда независимые переменные коррелируют друг с другом (т.е. имеет место мультиколлинеарность). Следствием этого является плохая обусловленность матрицы $X^T X$ и неустойчивость оценок коэффициентов регрессии. Оценки, например, могут иметь неправильный знак или значения, которые намного превосходят те, которые приемлемы из физических или практических соображений.

Метод стоит использовать, если:
\begin{itemize}
	\item сильная обусловленность;
	\item сильно различаются собственные значения или некоторые из них близки к нулю;
	\item в матрице $X$ есть почти линейно зависимые столбцы.
\end{itemize}

\subsection{Постановка задачи}

Решается задача регрессии. Применяется линейная модель (вообще говоря, один из признаков полагается константным для того, чтобы аппроксимирующая гиперплоскость не обязательно проходила через нуль, я не знаю, почему это практически всюду опускается): $  f(x, \beta) = \langle\beta, x\rangle  $
. В изначальной постановке полагается, что вектор $\beta$
 находится методом Обычных Наименьших Квадратов (ОНК):
 \[
 	\sum_{n = 1}^{N} (f(x_n, \beta) - y_n)^2 \longrightarrow \min_{\displaystyle \beta}
\]


Аналитическое решение данной задачи: $  \beta^{*} = (X^TX)^{-1}X^TY  $
, однако при вырожденности матрицы $  X^TX  $
 решение оказывается не единственным, а при ее плохой обусловленности — неустойчивым. Поэтому целесообразно ввести регуляризацию по параметру $  \beta  $
, например, $  L_2  $
.

Таким образом, приходим к следующей задаче минимизации (гребневая (ridge) регрессия):

\[
	Q(\beta)= \left \| Y - X\beta \right \|^2 + \lambda\left \|\beta \right \|^2 \longrightarrow \min_{\displaystyle \beta}
\]


где $ \left \|\beta \right \|^2 =\sum^{D}_{i=1} {\beta_i}^2,   $
 $  \lambda   $
 — параметр регуляризации(неотрицательное число).

\subsection{Вывод оптимальных весов}

Для нахождения оптимальных весов продифференцируем функционал по $ \beta  $
 и приравняем к 0:
 \[
 	\frac{\partial Q}{\partial \beta} = 2X^{T}(X\beta - Y) + 2\lambda\beta = 0
\]


\[
	(X^{T}X + \lambda I)\beta = X^{T}Y
\]


\[
	\beta^{*} =(X^{T}X + \lambda I)^{-1} X^{T}Y
\]

При увеличении параметра $  \lambda  $
 решение становится более устойчивым, но с другой стороны — смещенным. При уменьшении — приходим к задаче ОНК без регуляризации: имеем шанс переобучиться. Поэтому нужно искать что-то посерединке.

\section{Бэггинг и случайный лес}

\subsection{Bagging}

\textbf{Бэггинг} (bagging) --- это технология классификации, использующая композиции алгоритмов, каждый из которых обучается независимо. Результат классификации определяется путем голосования. Бэггинг позволяет снизить процент ошибки классификации в случае, когда высока дисперсия ошибки базового метода.

\subparagraph{Идея метода}

\emph{Бэггинг} – технология классификации, где в отличие от бустинга все элементарные классификаторы обучаются и работают параллельно (независимо друг от друга). Идея заключается в том, что классификаторы не исправляют ошибки друг друга, а компенсируют их при голосовании. Базовые классификаторы должны быть независимыми, это могут быть классификаторы основанные на разных группах методов или же обученные на независимых наборах данных. Во втором случае можно использовать один и тот же метод.

В~\emph{бэггинге~(bagging, bootstrap aggregation)} предлагается обучить некоторое
число алгоритмов~$b_n(x)$ с помощью метода~$\tilde \mu$, и построить итоговую композицию
как среднее данных базовых алгоритмов:
\[
    a_N(x)
    =
    \frac{1}{N}
    \sum_{n = 1}^{N}
        b_n(x)
    =
    \frac{1}{N}
    \sum_{n = 1}^{N}
        \tilde \mu(X)(x).
\]

\subsection{Random Forest}

Как мы выяснили, бэггинг позволяет объединить несмещенные,
но чувствительные к обучающей выборке алгоритмы в несмещенную
композицию с низкой дисперсией.
Хорошим семейством базовых алгоритмов здесь являются решающие деревья~---
они достаточно сложны и могут достигать нулевой ошибки
на любой выборке~(следовательно, имеют низкое смещение),
но в то же время легко переобучаются.

Метод~\emph{случайных лесов}~\cite{breiman01randomforest} основан на бэггинге над решающими деревьями,
см. алгоритм~\ref{alg:rf}.
Выше мы отметили, что бэггинг сильнее уменьшает дисперсию
базовых алгоритмов, если они слабо коррелированы.
В случайных лесах корреляция между деревьями понижается путем рандомизации
по двум направлениям: по объектам и по признакам.
Во-первых, каждое дерево обучается по бутстрапированной подвыборке.
Во-вторых, в каждой вершине разбиение ищется по подмножеству признаков.

\begin{centering}
	\begin{algorithm}[t]
	\caption{Random Forest}
	\label{alg:rf}
	    \begin{algorithmic}[1]
	        \FOR{$n = 1, \dots, N$}
	            \STATE Сгенерировать выборку~$\tilde X_n$ с помощью бутстрэпа
	            \STATE Построить решающее дерево~$b_n(x)$ по выборке~$\tilde X_n$:
	                \begin{itemize}
	                    \item дерево строится, пока в каждом листе не окажется не более~$n_{\min}$ объектов
	                    \item при каждом разбиении сначала выбирается~$m$ случайных
	                        признаков из~$p$, и оптимальное разделение ищется только среди них
	                \end{itemize}
	        \ENDFOR
	        \STATE Вернуть композицию~$a_N(x) = \frac{1}{N} \sum_{n = 1}^{N} b_n(x)$
	    \end{algorithmic}
	\end{algorithm}
\end{centering}


\section{Алгоритм градиентного бустинга}

Пусть дана некоторая дифференцируемая функция потерь~$L(y, z)$.
Будем строить взвешенную сумму базовых алгоритмов:
\[
    a_N(x)
    =
    \sum_{n = 0}^{N}
        \gamma_n b_n(x)
\]
Заметим, что в композиции имеется начальный алгоритм~$b_0(x)$.
Как правило, коэффициент~$\gamma_0$ при нем берут равным единице,
а сам алгоритм выбирают очень простым, например:
\begin{itemize}
    \item нулевым~$b_0(x) = 0$;
    \item возвращающим самый популярный класс~(в задачах классификации):
        \[
            b_0(x) = \argmax_{y \in \YY} \sum_{i = 1}^{\ell} [y_i = y]
        \]
    \item возвращающим средний ответ~(в задачах регрессии):
        \[
            b_0(x) = \frac{1}{\ell} \sum_{i = 1}^{\ell} y_i
        \]
\end{itemize}

Допустим, мы построили композицию~$a_{N - 1}(x)$ из $N - 1$ алгоритма,
и хотим выбрать следующий базовый алгоритм~$b_N(x)$ так, чтобы как можно сильнее
уменьшить ошибку:
\[
    \sum_{i = 1}^{\ell}
        L(y_i, a_{N - 1}(x_i) + \gamma_N b_N(x_i))
    \to
    \min_{b_N, \gamma_N}
\]

Ответим в первую очередь на следующий вопрос: если бы в качестве алгоритма~$b_N(x)$ мы
могли выбрать совершенно любую функцию, то какие значения ей следовало бы принимать
на объектах обучающей выборки? Иными словами, нам нужно понять, какие числа~$s_1, \dots, s_\ell$
надо выбрать для решения следующей задачи:
\[
    \sum_{i = 1}^{\ell}
        L(y_i, a_{N - 1}(x_i) + s_i)
    \to
    \min_{s_1, \dots, s_\ell}
\]
Понятно, что можно требовать~$s_i = y_i - a_{N - 1}(x_i)$,
но такой подход никак не учитывает особенностей функции потерь~$L(y, z)$
и требует лишь точного совпадения предсказаний и истинных ответов.
Более разумно потребовать, чтобы сдвиг~$s_i$ был противоположен производной функции потерь
в точке~$z = a_{N - 1}(x_i)$:
\[
    s_i
    =
    -
    \left.
    \frac{\partial L}{\partial z}
    \right|_{z = a_{N - 1}(x_i)}
\]
В этом случае мы сдвинемся в сторону скорейшего убывания функции потерь.
Заметим, что вектор сдвигов~$s = (s_1, \dots, s_\ell)$ совпадает
с антиградиентом:
\[
    \left(
        -\left.
        \frac{\partial L}{\partial z}
        \right|_{z = a_{N - 1}(x_i)}
    \right)_{i = 1}^{\ell}
    =
    -\nabla_z
    \sum_{i = 1}^{\ell}
        L(y_i, z_i)
    \big|_{z_i = a_{N - 1}(x_i)}
\]
При таком выборе сдвигов~$s_i$ мы, по сути, сделаем один шаг градиентного спуска,
двигаясь в сторону наискорейшего убывания ошибки на обучающей выборке.
Отметим, что речь идет о градиентном спуске в $\ell$-мерном пространстве предсказаний алгоритма
на объектах обучающей выборки.
Поскольку вектор сдвига будет свой на каждой итерации, правильнее обозначать его как~$s_i^{(N)}$,
но для простоты будем иногда опускать верхний индекс.

\section{Оценка качества кластеризации.}

Существует два подхода к измерению качества кластеризации: внутренний и внешний.
Внутренний основан на некоторых свойствах выборки и кластеров,
а внешний использует дополнительные данные~--- например, информацию об истинных кластерах.

Приведём несколько примеров внутренних метрик качества.
Будем считать, что каждый кластер характеризуется своим~\emph{центром}~$c_k$.
\begin{enumerate}
    \item Внутрикластерное расстояние:
        \begin{equation}
        \label{eq:intracluster}
            \sum_{k = 1}^{K}
            \sum_{i = 1}^{\ell}
                [a(x_i) = k]
                \rho(x_i, c_k),
        \end{equation}
        где~$\rho(x, z)$~--- некоторая функция расстояния.
        Данный функционал требуется минимизировать, поскольку в идеале
        все объекты кластера должны быть одинаковыми.
    \item Межкластерное расстояние:
        \[
            \sum_{i, j = 1}^{\ell}
                [a(x_i) \neq a(x_j)]
                \rho(x_i, x_j).
        \]
        Данный функционал нужно максимизировать, поскольку
        объекты из разных кластеров должны быть как можно менее похожими друг на друга.
    \item Индекс Данна~(Dunn Index):
        \[
            \frac{
                \underset{1 \leq k < k^\prime \leq K}{\min}
                    d(k, k^\prime)
            }{
                \underset{1 \leq k \leq K}{\max}
                    d(k)
            },
        \]
        где~$d(k, k^\prime)$~--- расстояние между кластерами~$k$ и~$k^\prime$~(например, евклидово расстояние
        между их центрами), а~$d(k)$~--- внутрикластерное расстояние для~$k$-го кластера~(например,
        сумма расстояний от всех объектов этого кластера до его центра).
        Данный индекс необходимо максимизировать.
\end{enumerate}

Внешние метрики возможно использовать, если известно истинное распределение объектов по кластерам.
В этом случае задачу кластеризации можно рассматривать как задачу многоклассовой классификации,
и использовать любую метрику оттуда~--- F-меру с микро- или макро-усреднением.

\section{Многослойный персептрон}

\subsection{Определение}

\textbf{Многослойный персептрон} --- нейронная сеть прямого распространения сигнала (без обратных связей), в которой входной сигнал преобразуется в выходной, проходя последовательно через несколько слоев.

Первый из таких слоев называют входным, последний - выходным. Эти слои содержат так называемые вырожденные нейроны и иногда в количестве слоев не учитываются. Кроме входного и выходного слоев, в многослойном персептроне есть один или несколько промежуточных слоев, которые называют скрытыми.

В этой модели персептрона должен быть хотя бы один скрытый слой. Присутствие нескольких таких слоев оправдано лишь в случае использования нелинейных \emph{функций активации}.

\subsection{Функции активации}

Наиболее часто в качестве функций активации используются следующие виды сигмоид:

Функция Ферми (экспоненциальная сигмоида):
\[
	f(s)= \frac{1}{1+e^{-2 \alpha s}}
\]

Рациональная сигмоида (при $\alpha=0$ вырождается в т. н. пороговую функцию активации):
\[
f(s)= \frac{s}{|s|+ \alpha}
\]

Гиперболический тангенс:
\[
	f(s)= \mathrm{th}\, \frac{s}{\alpha} = \frac{ e^{ \frac{s}{\alpha} } - e^{ - \frac{s}{\alpha}} }
	{e^{ \frac{s}{\alpha} } + e^{ - \frac{s}{\alpha}}}
\]
,

где $s$ — выход сумматора нейрона, $\alpha$ — произвольная константа.

Менее всего, сравнительно с другими сигмоидами, процессорного времени требует расчёт рациональной сигмоиды. Для вычисления гиперболического тангенса требуется больше всего тактов работы процессора. Если же сравнивать с пороговыми функциями активации, то сигмоиды рассчитываются очень медленно. Если после суммирования в пороговой функции сразу можно начинать сравнение с определённой величиной (порогом), то в случае сигмоидальной функции активации нужно рассчитать сигмоид (затратить время в лучшем случае на три операции: взятие модуля, сложение и деление), и только потом сравнивать с пороговой величиной (например, нулём). Если считать, что все простейшие операции рассчитываются процессором за примерно одинаковое время, то работа сигмоидальной функции активации после произведённого суммирования (которое займёт одинаковое время) будет медленнее пороговой функции активации в 4 раза.

\section{Chain rule для производной сложной функции. Алгоритм Backpropagation.}

\subsection{Backpropagation}

\textbf{Метод обратного распространения ошибки (Back propagation, backprop)} - алгоритм обучения многослойных персептронов, основанный на вычислении градиента функции ошибок. В процессе обучения веса нейронов каждого слоя нейросети корректируются с учетом сигналов, поступивших с предыдущего слоя, и невязки каждого слоя, которая вычисляется рекурсивно в обратном направлении от последнего слоя к первому.

\end{document}
